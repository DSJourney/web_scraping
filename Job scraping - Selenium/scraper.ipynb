{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting jobs from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Useful prior information](#info)\n",
    "- [Importing libraries](#imports)\n",
    "- [Defining functions](#functions)\n",
    "- [Running program](#exec)\n",
    "- [Saving data](#save)\n",
    "- [Next Steps](#steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=info></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Prior Information:\n",
    "- The main rule is to use API's over webscraper and [Indeed has an open source API.](https://opensource.indeedeng.io/api-documentation/) Having said this, I am not using this for any commercial purpose, I wanted to learn Selenium, so I used it instead of the API\n",
    "- [Selenium documentation](https://selenium-python.readthedocs.io/)\n",
    "- [Download Chromedriver](https://sites.google.com/a/chromium.org/chromedriver/downloads) and put it in the same folder or on a PATH you can easily locate\n",
    "- [Recommendations on webscraping](https://hackernoon.com/how-to-scrape-a-website-without-getting-blacklisted-271a605a0d94)\n",
    "- Use a [VPN](https://stackoverflow.com/a/59512170) or [Proxies.](https://www.quora.com/I-was-scraping-a-website-and-they-blocked-me-How-can-I-get-around-this) You might want to use [ProxiCrawl](https://proxycrawl.com/scraping-api-avoid-captchas-blocks) if you do not have a VPN\n",
    "- Check [what are robots.txt](https://www.cloudflare.com/learning/bots/what-is-robots.txt/) and [Indeed's robots.txt](https://www.indeed.com/robots.txt)\n",
    "- [The legality of webscraping](https://parsers.me/us-court-fully-legalized-website-scraping-and-technically-prohibited-it/)\n",
    "\n",
    "Even with the [LinkedIn vs HiQ](https://www.eff.org/deeplinks/2019/09/victory-ruling-hiq-v-linkedin-protects-scraping-public-data) case setting a precedent, be mindful of the ToS of every website. The following message can be found on [Indeed's Terms and Conditions](https://www.indeed.com/legal?hl=en&redirect=true) for all users:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "\n",
    "**2. Using our Site**\n",
    "\n",
    "Use of any automated system or software, whether operated by a third party or otherwise, to extract data from the Site (such as screen scraping or crawling) is prohibited. Indeed reserves the right to take such action as it considers necessary, including issuing legal proceedings without further notice, in relation to any unauthorized use of the Site. If you wish to make commercial use of the Site, if you wish to make use of the Site in any capacity other than that of a Jobseeker or Employer, or if you wish to purchase Indeed services that utilize the Site, you must have a prior written agreement with Indeed to do so, or have accepted Indeedâ€™s online terms of service. Please contact us for more information. We reserve the right at all times (but will not have any obligation) to terminate users, and reclaim usernames or URLs, for any reason.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=imports></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import selenium\n",
    "import pandas as pd\n",
    "import os\n",
    "import time \n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=functions></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_indeed(info_list):\n",
    "    \n",
    "    column = []\n",
    "    information = []\n",
    "\n",
    "    if 'title' in info_list:\n",
    "        column.append('title')\n",
    "        titles = []\n",
    "        x = [titles.append(i.find_element_by_tag_name('a').get_attribute('title'))\\\n",
    "             for i in driver.find_elements_by_tag_name('h2') if i.text != '']\n",
    "            \n",
    "        information.append(titles)\n",
    "\n",
    "    if 'company' in info_list:\n",
    "        column.append('company')\n",
    "        companies = []\n",
    "        x = [companies.append(i.text) for i in driver.find_elements_by_class_name('company') if i.text != '']\n",
    "        information.append(companies)\n",
    "    \n",
    "    if 'link' in info_list:\n",
    "        column.append('link')\n",
    "        links = []\n",
    "        x = [links.append(i.find_element_by_tag_name('a').get_attribute('href'))\\\n",
    "             for i in driver.find_elements_by_class_name('title') if i.text != '']\n",
    "        information.append(links)\n",
    "        \n",
    "    if 'date_listed' in info_list:\n",
    "        column.append('date_listed')\n",
    "        dates = []\n",
    "        x = [dates.append(i.text) for i in driver.find_elements_by_class_name('date') if i.text != '']\n",
    "        information.append(dates)\n",
    "        \n",
    "    if 'location' in info_list:\n",
    "        column.append('location')\n",
    "        location = []\n",
    "        x = [location.append(i.text) for i in driver.find_elements_by_class_name('location.accessible-contrast-color-location') if i.text != ''] \n",
    "        # explanation on why we need the full-stops: https://stackoverflow.com/questions/58422998/selenium-python-find-elements-by-class-name-returns-nothing\n",
    "        information.append(location)\n",
    "        \n",
    "    if 'salary' in info_list:\n",
    "        column.append('salary')\n",
    "        salary = []\n",
    "        for i in driver.find_elements_by_class_name('jobsearch-SerpJobCard.unifiedRow.row.result.clickcard'):\n",
    "            try:\n",
    "                salary.append(i.find_elements_by_class_name('salaryText')[0].text)\n",
    "            except:\n",
    "                salary.append('None')\n",
    "        information.append(salary)\n",
    "                \n",
    "    if 'remote' in info_list:\n",
    "        column.append('remote')\n",
    "        remote = []\n",
    "        for i in driver.find_elements_by_class_name('sjcl'):\n",
    "            try:\n",
    "                remote.append(i.find_elements_by_class_name('remote')[0].text)\n",
    "            except:\n",
    "                remote.append('None')\n",
    "        information.append(remote)\n",
    "        \n",
    "    if 'rating' in info_list:\n",
    "        column.append('rating')\n",
    "        rating = []\n",
    "        for i in driver.find_elements_by_class_name('sjcl'):\n",
    "            try:\n",
    "                rating.append(i.find_elements_by_class_name('ratingsContent')[0].text)\n",
    "            except:\n",
    "                rating.append('None')\n",
    "        information.append(rating)\n",
    "        \n",
    "    if 'easy_apply' in info_list:\n",
    "        column.append('easy_apply')\n",
    "        easy = []\n",
    "        for i in driver.find_elements_by_class_name('jobsearch-SerpJobCard.unifiedRow.row.result.clickcard'):\n",
    "            try:\n",
    "                easy.append(i.find_elements_by_class_name('iaLabel.iaIconActive')[0].text)\n",
    "            except:\n",
    "                easy.append('None')\n",
    "        information.append(easy)        \n",
    "        \n",
    "        \n",
    "    jobs = {}\n",
    "    \n",
    "    for j in range(len(column)):\n",
    "        jobs[column[j]] = information[j]\n",
    "\n",
    "    \n",
    "    return jobs\n",
    "\n",
    "def get_descriptions_indeed():\n",
    "    \n",
    "    descriptions = []\n",
    "    \n",
    "    ids = [i.find_element_by_tag_name('a').get_attribute('id') for i in driver.find_elements_by_tag_name('h2') if i.text != '']\n",
    "    \n",
    "    for job in ids:\n",
    "        driver.find_elements_by_id(job)[0].click()\n",
    "\n",
    "        time.sleep(4) #https://hackernoon.com/how-to-scrape-a-website-without-getting-blacklisted-271a605a0d94\n",
    "\n",
    "        driver.switch_to.frame(driver.find_element_by_tag_name(\"iframe\"))\n",
    "        descriptions.append(driver.find_element_by_id('jobDescriptionText').text)\n",
    "\n",
    "        driver.switch_to.parent_frame()\n",
    "        time.sleep(4)\n",
    "    \n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=exec></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify what jobs you want to search for\n",
    "keywords = 'machine learning engineer'\n",
    "location = 'California'\n",
    "\n",
    "#specify driver path in my case I have it in the same folder as this document\n",
    "DRIVER_PATH = 'chromedriver'\n",
    "driver = webdriver.Chrome(executable_path = DRIVER_PATH)\n",
    "\n",
    "#determine the website (in our case indeed.com)\n",
    "driver.get('https://indeed.com')\n",
    "time.sleep(2)\n",
    "\n",
    "#searches the keyword specified above\n",
    "search_job = driver.find_elements_by_id('text-input-what')[0]\n",
    "search_job.send_keys([keywords])\n",
    "\n",
    "#search location I use COMMAND because it is a mac computer (in a Windows computer change to CONTROL)\n",
    "search_job = driver.find_elements_by_id('text-input-where')[0]\n",
    "search_job.send_keys(Keys.COMMAND,\"a\",Keys.BACKSPACE)\n",
    "search_job.send_keys([location])\n",
    "time.sleep(2)\n",
    "\n",
    "#this clicks the \"find jobs\" button\n",
    "initial_search_button = driver.find_element_by_class_name('icl-WhatWhere-buttonWrapper')\n",
    "initial_search_button.click()\n",
    "\n",
    "#this will tell you how many jobs there currently are for your search\n",
    "print(driver.find_element_by_id('searchCountPages').text)\n",
    "page_counter = 1\n",
    "\n",
    "#specify what information you want to extract\n",
    "info_list = ['title', 'company', 'link', 'date_listed', 'location', 'salary', 'remote', 'rating', 'easy_apply']\n",
    "df = pd.DataFrame(get_info_indeed(info_list))\n",
    "\n",
    "#this calls the description function to get detailed information\n",
    "df['description'] = get_descriptions_indeed()\n",
    "\n",
    "#clicks on \"next page\"\n",
    "driver.find_element_by_xpath(\"//a[@aria-label='Next']\").click()\n",
    "print(\"Navigating to Next Page\")\n",
    "page_counter += 1\n",
    "print(\"You are currently in page \", page_counter)\n",
    "time.sleep(3)\n",
    "\n",
    "#on the second page normally a pop-up appears asking you to put an email alert, this closes it\n",
    "if driver.find_element_by_id(\"popover-x\").is_displayed() == True:\n",
    "    driver.find_element_by_id('popover-x').click()\n",
    "    time.sleep(3)\n",
    "\n",
    "else:\n",
    "    pass\n",
    "\n",
    "#extract data from the second page\n",
    "new_df = pd.DataFrame(get_info_indeed(info_list))\n",
    "new_df['description'] = get_descriptions_indeed()\n",
    "df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "# for the next pages we can create a while loop    \n",
    "while True:\n",
    "\n",
    "    try:   \n",
    "        driver.find_element_by_xpath(\"//a[@aria-label='Next']\").click()\n",
    "        print(\"Navigating to Next Page\")\n",
    "        page_counter += 1\n",
    "        print(\"You are currently in page \", page_counter)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        new_df = pd.DataFrame(get_info_indeed(info_list))\n",
    "        new_df['description'] = get_descriptions_indeed()\n",
    "        df = pd.concat([df, new_df], ignore_index=True)\n",
    "\n",
    "    except (TimeoutException, WebDriverException) as e:\n",
    "        print(\"Last page reached or you were kicked out\")\n",
    "        break\n",
    "\n",
    "driver.close()\n",
    "driver.quit()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>link</th>\n",
       "      <th>date_listed</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>remote</th>\n",
       "      <th>rating</th>\n",
       "      <th>easy_apply</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Intern - Interpretable Machine Learning RD Und...</td>\n",
       "      <td>Sandia National Laboratories</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=bcd9484e9c9e9...</td>\n",
       "      <td>10 days ago</td>\n",
       "      <td>Livermore, CA 94551</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.2</td>\n",
       "      <td>None</td>\n",
       "      <td>What Your Job Will Be Like\\n\\nWe are seeking a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Apple</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=20a00c5efac63...</td>\n",
       "      <td>8 days ago</td>\n",
       "      <td>Santa Clara Valley, CA 95014</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4.2</td>\n",
       "      <td>None</td>\n",
       "      <td>Summary\\nPosted: Oct 21, 2020\\nWeekly Hours: 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>ADAPT Technology LLC.</td>\n",
       "      <td>https://www.indeed.com/company/Adapt-Technolog...</td>\n",
       "      <td>9 days ago</td>\n",
       "      <td>Mountain View, CA 94043</td>\n",
       "      <td>$85 - $90 an hour</td>\n",
       "      <td>Temporarily remote</td>\n",
       "      <td>None</td>\n",
       "      <td>Easily apply</td>\n",
       "      <td>Machine Learning Engineer - Intelligent Mobili...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "27  Intern - Interpretable Machine Learning RD Und...   \n",
       "28                          Machine Learning Engineer   \n",
       "29                          Machine Learning Engineer   \n",
       "\n",
       "                         company  \\\n",
       "27  Sandia National Laboratories   \n",
       "28                         Apple   \n",
       "29         ADAPT Technology LLC.   \n",
       "\n",
       "                                                 link  date_listed  \\\n",
       "27  https://www.indeed.com/rc/clk?jk=bcd9484e9c9e9...  10 days ago   \n",
       "28  https://www.indeed.com/rc/clk?jk=20a00c5efac63...   8 days ago   \n",
       "29  https://www.indeed.com/company/Adapt-Technolog...   9 days ago   \n",
       "\n",
       "                        location             salary              remote  \\\n",
       "27           Livermore, CA 94551               None                None   \n",
       "28  Santa Clara Valley, CA 95014               None                None   \n",
       "29       Mountain View, CA 94043  $85 - $90 an hour  Temporarily remote   \n",
       "\n",
       "   rating    easy_apply                                        description  \n",
       "27    4.2          None  What Your Job Will Be Like\\n\\nWe are seeking a...  \n",
       "28    4.2          None  Summary\\nPosted: Oct 21, 2020\\nWeekly Hours: 4...  \n",
       "29   None  Easily apply  Machine Learning Engineer - Intelligent Mobili...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=save></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'30_10_2020'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today().strftime(\"%d_%m_%Y\")\n",
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/'+today+'_'+keywords+'_'+location+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=steps></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a set of improvements someone with some time could work on:\n",
    "- Implement Advanced Search\n",
    "- Automatically apply to companies that accept \"easy apply\"\n",
    "- Implement stopping points (sometimes you do not want all the pages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
